CC - кэш когерентные системы - cash coherent
Какие системы есть? Можно взять 2 физических процессора по 128 ядер с шиной между ними по 12 шин памяти. 
Процессор на 128 ядер - 8 пластин по 16 ядер. 
Даже для систем с 2мя сокетами скорость передачи данных в память похожа на старые с 4мя сокетами из-за усложнённой конструкции. 
Есть системы с 4мя сокетами, при котором скорость передачи в дальнюю память падает до 8 раз. 
Систем с 8ю сокетами нет, потому что CC >= 2/3, то есть для синхронизации уходит 2/3 трафика и это жесть. 
Системы с разделённой памятью обладают общей шиной, с помощью которой они могут вместе общаться. Виртуальная память каждого узла выглядит как одна большая виртуальная память. Скорость обращения к чужой памяти падает до 1000 раз, поэтому так делать стоит минимум. 
### Память
1980гг - 16.7 MHz
2024гг - 20 MHz
Прогресса почти нет. 
Для справки - это скорость передачи по 1 байту но никто по 1 байту не передаёт, а сразу по строке кэша. До 12 контроллеров в 1 сокете, которые режут память для передачи. 
Эффективно можно обмениваться пачками по много байт, например по 512 байт. 
Важно читать память подряд по большим блокам памяти, потому что он обычно читает сразу много. 

### Диски
1 блок - обычно читает по 32/64 Кб за раз, потому что меньше уже не может. 
Если поставить 10 дисков, то скорость записи до 10 раз быстрее будет, но возникает другая проблема. Иногда у дисков (вращающихся) возникают отказы. И увеличивая количество дисков увеличивается и вероятность отказа пропорционально, что всю систему покарраптит. Поэтому нужно хранить ещё 1 бит для обнаружения отказа. Это память коррекции ошибок. 
Поэтому если к N дискам добавить ещё 1, который будет контролировать ошибки, то ошибки будут отслеживаться, но будет небольшое замедление за счёт обработки ошибок. Но иногда ещё и добавляют 2 доп диска, потому что если один умрёт, этот его заменит. 
Допустим мы смогли получить систему на Пб. Если взять несколько таких блоков, то можно составить Блок из таких блоков. Потом взять ещё несколько БЛОКОВ ил Блоков, но так делать бесконечно нельзя. 

### GPU - Graph Processor Units
SM - streaming multiprocessor - 32/64/128 ядер
Эти ядра гораздо слабее ЦП, кэш очень маленький. Задача каждого ядра - обрабатывать свою инструкцию. 
GPU состоит из огромного количество SM и скорость передачи данных в РАЗЫ больше. Архитектура совершенно другая. 
Теперь есть ядра с 16битной плавающей точкой. 

Можно соединить CPU и GPU шиной PCI express. К ней же подключен ethernet. 

## Системы с распределённой памятью
Есть много плат с процессорами, соединённые общим коммуникационным каналом, шиной. Рассмотрим возможные архитектуры. 
Системы с такой общей памятью называется SMP - symm multiproc system
Бывают коммутирующие или поточечные шины
У коммутирующих шин есть коммутатор, соединяющий все порты между собой. 

У каждого адаптера есть 4 выхода и они составляют матрицу 6 х 8, которые влезают в одну стойку. 
```
S C I системы


| | | | | | | |
0-0-0-0-0-0-0-0-(с другой стороны соединён с первым)
| | | | | | | |
0-0-0-0-0-0-0-0-(с другой стороны соединён с первым)
| | | | | | | |
0-0-0-0-0-0-0-0-(с другой стороны соединён с первым)
| | | | | | | |
0-0-0-0-0-0-0-0-(с другой стороны соединён с первым)
| | | | | | | |
0-0-0-0-0-0-0-0-(с другой стороны соединён с первым)
| | | | | | | |
0-0-0-0-0-0-0-0-(с другой стороны соединён с первым)
| | | | | | | |
c c c c c c c c

д д д д д д д д 
р р р р р р р р 

с с с с с с с с 
т т т т т т т т 
о о о о о о о о 
р р р р р р р р 
```
И в такой системе провода могли отваливаться из-за вибрации. 
Поэтому победила коммутирующая система, в которой каждый адаптер имеет 1 выход и присоединяется к общему коммутатору. 

non-blocking - каждая пара портов обменивается с другими параллельно. Решает скорость коммутации. 

Носитель - провод платы до адаптера - медь/оптика. 
Скорости:
Ethernet - 1GB/sec
Медь - <= 100 MB/sec
Ethernet - Infiniband - 10GB/sec. Основное отличие от Ethernet RDMB - Remote Direct Binary Access
Infiniband - 25 GB/sec
4x10 = 40 GB/sec - 10 GHz
2x25 = 1x50 = 50 GB/sec - 50 GHz
4x25 = 1x100 = 100 GB/sec
4x50 = 200 GB/sec
4x100 = 400 GB/sec

Bandwidth - ширина канала?
Latency - задержка - возможность передавать маленькие данные. 
В Ethernet измеряется в ms
В Infiniband - в ns
Разность в цене пропорциональна скорости. 

Все коммутаторы Infiniband (IB) - non-blocking, full bandwidth
Eternet умеет делать широковещательные запросы. Broadcast за бесплатно
Infiniband научился при определённых насройках point to point (P2P) широковещательные запросы только определённым за log(p) операций. 

Не более 36 подключений на адаптер, но придётся тратить порты. Если по 4 на подключение между двумя, то будет 32 + 32. А Ели хотим 1000? 
Система сложная, будет многоуровневая неоднородность доступа к памяти. 

### Типичный кластер
Есть IB - вычислительная среда с узлами. Самому узлу нужно как-то исполняемый файл отправить

# Практикум
Есть одномерный массив и количество потоков. Ответ от количества потоков зависеть не должен
`./a.out p filename`
`RESULT p: ...`
`RESULT 4: 1 2 3`
Как идёт проверка:
```bash
for ((p = 1; p <= 20; p++)); do ./a.out $p 20 a.txt; done
```

```bash
for ((p = 1; p <= 20; p++)); do
./a.out $p 20 a.txt; done
| grep RESULT
```

```cpp
printf("RESULT %2d: ", p);
for (i = 0; i < n; i++) {
	printf("%8.2e", a[i]);
}
printf("\n");
```

### Нужно сделать балансировку загруженности
Разрезаем n / p
$k*n/p <= \dots < (k + 1) * n / p$ 

```cpp
class results
{
public:
	double prev = 0;
	int count = 0;
	double next = 0;
	int num_change;
	// ...
};
```