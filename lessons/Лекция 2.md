В прошлый раз узнали про конвейер. Он смог кратно поднять тактовую частоту. Теперь процессор работает быстрее памяти. Нужно организовать КЭШ-память. Процессор может брать 32-64 байта памяти. Не нужно прыгать по разным адресам памяти. Одномерные массивы - хорошо, двумерные - проблема. Рассмотрим произведение матриц. 
C = A\*B
A = (aij)    a + i * n + j
B = (bij)    b + i * n + j
C = (cij)    c + i * n + j
```
for k in range(n):
	sum += aik * bkj
```
```
for i
	for j
		for k

или

for j
	for i
		for k
```

Структура:
```
A:
a, a+1...       a + n, ...     a + 2n, ...
|______________|______________|______________|______________|______________|
B:
b, b+1...       b + n, ...     
|______________|______________|______________|______________|______________|
C:
c, c+1...       c + n, ...     
|______________|______________|______________|______________|______________|
```

Если предположить, что вектор длины n помещается в кэш L1, то всё ок
Но всё-таки кэш 1го уровня - это 32/64 килобайта, это мало, а массивы могут быть огромные. Если массив больше нескольких тысяч Кб, то мы вообще ничего не сможем сделать, и пересчёт кэша будет очень частым.

Рассмотрим матрицу n x n, n = k x m + l
m - параметр (размер блока)
m\*\*2 - максимальный размер L1
Рассмотрим матрицу матриц:
```
	(A11:m x m)(A12:m x m) ... A(1k:m x m)(A1,k+1:m x l)
	()
	()
A = ()
	()
	()
	(Ak+1,1:m x l)...                     (Ak+1,k+1:l x l)

```

```
cij = 0
for s in range(1, k + 2):
	Cij += AisBsj
	
```

m подбираем под процессор и количество матриц, которые используем
```c++
for (i=0; i <= k; i++) {
	for (j=0; j <= k; j++){
		cni = (i < k ? m : l);
		cnj = (j < k ? m : l);
		// Обнулить блок С
		for(s = 0; s <= k; s++){
			// Вычисляем размер блока Aij
			// Вычисляем размер блока Bij
			// перемножаем
			Cij += Ais * Bsj; // ещё тройной цикл
		}
	}
}
```

```
c_p,r = 0
for q in range(q0):
	c_p,r += akq * bqr
for p
	for r
		for q
			cpr += akq * bqr

Есть блок матрицы С, разворачиваем на блоки 3 х 3
____________________.   ____________________     ____________________
|					|. |					|   |			   ||| 	 |
|					|. |					|   |			   ||| 	 |
|			***		| =|--------------------| x |			   ||| 	 |
|			***		|. |--------------------|   |			   ||| 	 |
|			***		|. |--------------------|   |			   ||| 	 |
____________________.   ____________________     ____________________

```
блок m мы выбирали, например тот, который делится на 3. Теперь мы можем удобно равернуть цикл

``` c++
void mult(double * a, double * b, double * c, int n, int m) {
	int ...
	k = n / m; l = n - k * m; // n = k * m + l
	// Если поделилось нацело, то блоков k, иначе k + 1
	int bl = (l != ? k + 1 : k); // Самый вероятный случай рассматриваем
	for (i = 0; i < bl; i++) {
		for (j = 0; j < bl; j++) {
			// размер блока С -- v x h
			v = (i < k ? m : l); // vertical
			h = (j < k ? m : l); // horizontal
			// начало блока С
			double * pc = c + i * n * m + j * m;
			for (r = 0; r < v; r++){ // обнулять блок r x h
				for (t = 0; t < h; t++) {
					pc[r * m + t] = 0;
				}
			}
			for (s = 0; s < bl; s++) {
				// C(v x h) += A(v x _) * B(_ x h), нужно найти _
				ah = (s < k ? m : l);
				double * pa = a + i * n * m + s * m; // Ais
				double * pb = b + i * n * m + j * m; // Bsj
				int v3 = v % 3;
				int h3 = h % 3;
				// напишем ту часть, что касается остатка
				for (r = 0; r < v3; r++){
					for (t = 0; t < h3; t++){
						sum = 0;
						for (q = 0; q < ah; q++){
							sum += pa[r * n + q] * pb[q * n + t];
						}
						pc[r * n + t] += sum;
					}
					for ( ; t < h; t += 3) {
						s00 = 0;
						s01 = 0;
						s02 = 0;
						for (q = 0; q < ah; q++) {
							s00 += pa[r * n + q] * pb[q * n + t];
							s01 += pa[r * n + q] * pb[q * n + t + 1];
							s02 += pa[r * n + q] * pb[q * n + t + 2];
						}
						pc[r * n + t] += s00;
						pc[r * n + t + 1] += s01;
						pc[r * n + t + 2] += s02;
					}
				}
				for (; r < v; r += 3) {
					for (t = 0; t < h3; t++){
						s00 = 0;
						s10 = 0;
						s20 = 0;
						for (q = 0; q < ah; q) {
							s00 += pa[r * n + q] * pb[q * n + t];
							s10 += pa[(r + 1) * n + q] * pb[q * n + t];
							s00 += pa[(r + 2) * n + q] * pb[q * n + t];
						}
						pc[r * n + t] += s00;
						pc[(r + 1) * n + t] += s10;
						pc[(r + 2) * n + t] += s20;
					}
				}
				// переходим к основному циклу
				for (; t < h; t += 3) {
					s00 = 0;
					s01 = 0;
					s02 = 0;
					s10 = 0;
					s11 = 0;
					s12 = 0;
					s20 = 0;
					s21 = 0;
					s22 = 0;
					for (q = 0; q < ah; q++) {
						s00 += pa[r * n + q] * pb[q * n + t];
						s01 += pa[r * n + q] * pb[q * n + t + 1];
						s02 += pa[r * n + q] * pb[q * n + t + 2];
						s10 += pa[(r + 1) * n + q] * pb[q * n + t];
						s11 += pa[(r + 1) * n + q] * pb[q * n + t + 1];
						s12 += pa[(r + 1) * n + q] * pb[q * n + t + 2];
						s20 += pa[(r + 2) * n + q] * pb[q * n + t];
						s21 += pa[(r + 2) * n + q] * pb[q * n + t + 1];
						s22 += pa[(r + 2) * n + q] * pb[q * n + t + 2];
					}
					pc[r * n + t] += s00;
					pc[r * n + t + 1] += s01;
					pc[r * n + t + 2] += s02;
					pc[(r + 1) * n + t] += s10;
					pc[(r + 1) * n + t + 1] += s11;
					pc[(r + 1) * n + t + 2] += s12;
					pc[(r + 2) * n + t] += s20;
					pc[(r + 2) * n + t + 1] += s21;
					pc[(r + 2) * n + t + 2] += s22;
				}
			} // s
		} // j
	} // i
} // func
```
Ускорение в 10-12-14 раз! Хотя просто переставили скобки!

 Важное уточнение по скорости:
```c++
for (i = 0; i < n; i++){
	for (j = 0; j < n; j++){
	c[i * n + j] = 0;
	s = 0;
		for (s = 0; s < n; s++){
			c[i * n + j] += a[i * n + s] * b[s * n + j];
			s += a[i * n + s] * b[s * n + j]; // это быстрее, так как мы не обращаемся к памяти
		}
	}
}
```

В классическом же алгоритме он просто брал данные из памяти. ~10% работал и ~10% стоял. Теперь, когда мы смогли нагрузить процессор по максимуму, мы можем распараллелить, ведь шина памяти занята _не постоянно_. Цель: считать **быстрее**.
Как может выглядеть распараллеленый метод Гаусса?
Блочный метод Гаусса
```
A11(m x m)    A12(m x m)...     A1,k+1(m x l)    | B1(m)
A21(m x m)    A22(m x m)...     A2,k+1(m x l)    | B2(m)
...                                              |
Ak1(m x m)    Ak2(m x m)...     Ak,k+1(m x l)    | Bk(m)
Ak+1,1(m x m) Ak2(m x m)...     Ak+1,k+1(l x l)  | Bk+1(l)
________________________________________________________________
A11 -> C     D = C**(-1)
Aij -= Ai1 * A1j
________________________________________________________________
E11(m x m)    A12(m x m)...     A1,k+1(m x l)    | B1(m)
0             A22(m x m)...     A2,k+1(m x l)    | B2(m)
...                                              |
0             Ak2(m x m)...     Ak,k+1(m x l)    | Bk(m)
0             Ak2(m x m)...     Ak+1,k+1(l x l)  | Bk+1(l)
________________________________________________________________
...
________________________________________________________________
E11(m x m) A12(m x m)...         A1k(m x m) A1,k+1(m x l)
0          E22(m x m)...         A1k(m x m) A2,k+1(m x l) 
...
0          0...                  0          Ek+1,k+1(l x l)
```
Это прямой ход Гаусса

Обратный метод Гаусса:
```
Xk(m) = Bk(m) - ... не успел
```

### Применимость
```
1000
0100
0010
0001
____
0100
1000
0001
0010 - к этой матрице метод Гаусса неприменим, даже к блокам 2х2 и 3х3
```
Скорость:
```
^
|                 *
|*               *
| **           **
|   **      ***
|______****_____________________->
```

### LU Разложение
aij = sum(s=0, n, b_is * u_sj)

Aij = sum(s=1, min(i, j), Lis\*Usj)
j=1
Ai1 = sum(s=1, min(i, 1), Lis\*Us1) = Li1 \* U11
Ai1 = Li1U11
A11 = L11U11 - LU разложение для обычн матр
=> L11, U11
Затем Li1 = Ai1 \* U_11^-1
=> все элементы 1го столбца
A1j = sum(s=1, min(1, j), L1sUsj) = L11U1j
=> U1j = L11^-1 * A1j
Aij = sum(s = 1, max(i, j), LisUsj) = sum(s=1, j, LisUsj) = sum(s=1, j-1, LisUsj + LijUjj)
LijUjj = (Aij - sum(s=1, j-11, LjsUsj))  -  LU раз
i=j
LjjUjj = (Ajj - sum(s=1, j-11, LjsUsj))
...

### Решить:
1) A = LU
	Ax=B
	1) Ly = b
	2) Ux = y
2) A^-1 = (LU)^-1 = U^-1 * L^-1
	B = \[b1, ..., bn\]
	AB = \[Ab1, ..., Abn]
	ej - столб ед матр
	B = \[b1, ..., bn\]
	AB = \[Ab1, ..., Abn]
	B = \[x1, ..., xn\]
	AB = \[Ax1, ..., Axn] = \[e1, ..., en] = E
	=> B=A^-1

### Метод Холецкого
### Метод Жордана
Гаусс (2/3)n\*\*3 + O(n^2)
Жордан n\*\*3 + O(n^2)

### Метод вращений
```
x1
x2

t(phi) = cos phi  -sin phi
		 sin phi   cos phi

cos phi =  x1/(sqrt(x1**2 + x2**2))
sin phi = -x2/(sqrt(x1**2 + x2**2))
||x|| = sqrt(x1**2 + x2**2)

			 /X1 \          /1   \
T1n...T13T12 |...| = ||x1|| |0...|
			 \Xn /          \0   /
			 
```

### Метод вращений
U(x) = E - 2x\*transpose(x)

```
x = +-(y - ||y||e)/ (||y - ||y||e||)
```