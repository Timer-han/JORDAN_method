```c
struct A
{
	int n;
	char s[20] = {0}; // заполнение нулями
	double v;
};

A x;
```

```c
class A
{
public:
	int n;
	char s[20] = {}; // заполнение нулями
	double v = 0.;
};

A x;
```

Хотим отправить с помощью MPI объект x. Есть 3 варианта:
1) Создание нового типа данных
2) Упаковка перед отправкой/распаковка при получении
3) Перессылка неформатированных данных

### Создание типа
n - число полей в типе
{$c_i$, $t_i$, $d_i$} - n элементов описания каждого типа
$c_i$ - количество данных
$t_i$ - имеющийся тип
$d_i$ - смещение от начала объекта

Рассмотрим `class A`
3, {1, MPI_INT, 0}, {20, MPI_CHAR, 4}, {20, MPI_DOUBLE, 24}
Но смещение может быть кривым, ведь структура может быть невыровнена.
Например, если инт идёт раньше дабла, то будет пустой пробел в 4 бита в структуре

```cpp
struct A
{
	int n;
	char s[20];
	double v;
};

A a;
size_t t1 = (size_t)(&a.n) - (size_t)(&a);
size_t t2 = (size_t)(&a.s) - (size_t)(&a);
size_t t3 = (size_t)(&a.v) - (size_t)(&a);
// Вычислили смещения
```

```fortran
size_t MPI_Aint
&      MPI_Address(&x, &y) y = &x
```

```cpp
int MPI_Type_Struct(
	int count,            // число полей
	int c[],              // количество в каждом поле, массив длиной count
	MPI_Aint d[],         // смещение, массив длиной count
	MPI_Datatype t[],     // массив длиной count
	MPI_Datatype *newtype // куда положить новый тип
)
// Должна быть сделана локально на каждой машинке, 
// чтобы можно было пользоваться структуркой


MPI_Aint d[3] = {t1, t2, t3};
MPI_Datatype t[3] = {MPI_INT, MPI_CHAR, MPI_DOUBLE};
int c[3] = {1, 20, 1};
MPI_Type_struct(3, c, d, t, &new_type);



struct B
{
	A a;
	double z;
};

MPI_Datatype t2[] = {newtype, MPI_DOUBLE};
MPI_Aint d2[] = {...};
int c[2] = {1, 1}
MPI_Type_struct(...);

MPI_Type_commit(
	MPI_Datatype *newtype
) // нужно вызвать, если хотим использовать структуру из новой структуры
MPI_Send(...)

int MPI_Type_free(MPI_Datatype *newtype);
```

То есть с точки зрения мы в MPI создали новый тип! MPI - более объёктно-ориентированный, чем си/с++

### Упаковка/распаковка
Передаём адрес на начало структуры
При добавлении, переменная "указателя" продвигается дальше, обновляется сама
Распаковка в обратном порядке

```cpp
int MPI_Pack(
	void *data,
	int count,
	MPI_Datatype type,
	// то что упаковываем

	void *buf,
	int buf_size,
	int *pos, // тот самый указатель
	MPI_Comm comm,
);

// MPI_Send/MPI_Recv используют MPI_Pack??

// Как узнать размер буфера
int MPI_Pack_size(
	void *buf,
	int count,
	MPI_Datatype type,
	int *size // сюда сохранится сам размер
)

int MPI_Unpack(
	void *buf,
	int buf_size,
	int *pos, // тот самый указатель

	void *data,
	int count,
	MPI_Datatype type,
	// то что отправлялось

	MPI_Comm comm,
);
```

`struct A` ---> buf ---> send ---> recv в buf ---> `struct A`

Что делается на самом деле?

```cpp
struct A ...

A a;
// ПРЕДПОЛАГАЕМ, ЧТО СИСТЕМЫ ОДИНАКОВЫЕ

MPI_Send(&a, sizeof(a), MPI_Byte, ...);
// это неформатированные данные
```

```cpp
int MPI_Type_vector(
	int count,
	int block, // размер блока
	int stride, // расстояние между элементами вектора
	MPI_Datatype type,
	MPI_Datatype *newtype // указатель с ответом
)

MPI_Datatype column_t;
MPI_Type_vector(n, 1, n, MPI_DOUBLE, &column_t);
MPI_Type_commit(&column_t);
// Теперь можно пользоваться!

MPI_Type_free(&column_t)
```

## Создание групп процессоров
Неоднородный доступ к узлам
Группа задаётся типом `MPI_Group`
Идентификатор группы задаётся типом `MPI_Comm`

1) Идентификатор имеющейся группы (вначале `MPI_COMM_WORLD`)
2) Получить описание группы типа `MPI_Group`
3) Создать подгруппу
4) Создание идентификатора подгруппы
5) Теперь можно его использовать в обмене

#### Получить группу по идентификатору

```cpp
int MPI_Comm_group(
	MPI_Comm comm,
	MPI_Group *group // сюда вернут описание самой группы
)

```

#### Создание подгруппы
```cpp
int MPI_Group_incl(
	MPI_Group group,
	int n, // сколько процессов будет в новой подгруппе
	int *ranks, // номера из имеющейся группы, которые войдут в подгруппу
	MPI_Group *newgroup // результат - новая группа
)
```

#### Создание идентификатора
```cpp
int MPI_Comm_create(
	MPI_Comm comm, // идентификатор подгруппы, которой является новая группа
	MPI_Group_newgroup,
	MPI_Comm *newcom // ответ
);

// В конце освобождаем выделенную память
int MPI_Comm_free(MPI_Comm newcom);
```

#### Example
```cpp
int p, k;
MPI_Comm comm = MPI_COMM_WORLD;
MPI_Comm_size(comm, &p); // количество в группе
MPI_Comm_rank(comm, &k); // номер процесса в группе процессов

MPI_Group group_all;
MPI_Group group_half;
MPI_Comm comm_half;

int *ranks; // столько элементов, сколько в группе
int size = (p + 1) / 2;

ranks = new int[size];
if (ranks == nullptr) //...;

for (int i = 0; i < size; i++) {
	ranks[i] = i;
}

MPI_Comm_group(comm, &group_all);
MPI_Group_incl(group_all, sizem ranks, &group_all);

MPI_Comm_create(comm, group_half, &comm_half);
//...

MPI_Send(..., comm_half);
//...

MPI_Comm_free(comm_half);
```