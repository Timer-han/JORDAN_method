Программирование систем с распределённой памятью - 3 способа
1) Новый язык. Но далеко эта идея не прошла, потому что нужен парсер и оптимизатор. Все нынешние компиляторы разрабатываются >= 25 лет, поэтому не вариант
2) Комментарий в обычный язык. Например 
```cpp
//parallel
for (i = 0; i < n; i++)
```
Нужно переписывать компилятор. Но компилятор не сможет сам расспараллелить, потому что нужно менять алгоритм. 
3) Библиотека для стандартных языков
Этот способ победил
- pthread

### MPI - Message Passing Interface
1) Вначале стандарт:
	- Верхний уроевнь (должна работать везде)
	- Нижний уровень (сам код)

2) Несколько реализаций 
	- Мичиганский Mpich
	- lam - los alamos
	- Open MPI
3) Открытые

MPI вначале появился для FORTRAN
Потом появилось и для C/C++
При компиляции нужно добавить путь к инсталяции MPI
```
gcc -I путь file.c
gcc -lpthread
	-libpthread
gcc -pthread
gcc -L path -lmpi
```
Скрипт bash
```bash
mpicc = gcc -L .. -I путь -lmpi
mpicxx = g++ ...
mpirun -np 4 ./a.out 1000 30
# 4 - число проц
# -np - num proc
=
mpiexec
```

```cpp
#include "mpi.h"
#include <pthread.h>
```

```
MPI_1 - устарел
MPI_2 - пользуемся
MPI_3 - существует
```

### Пользуемся Intel MPI
`#include "mpi.h"` - ДОЛЖНО БЫТЬ ПЕРВЫМ, ДО ВКЛЮЧЕНИЯ ВСЕХ ДРУГИХ БИБЛИОТЕК

Потому что mpi переопределяет параметры/макросы некоторых библиотек

#### 2.
Все функции, константы начинаются на 
MPI_A...
MPI_B...
...

#### 3.
```cpp
int MPI_Name(...);
double MPI_Wtime(void);
double MPI_Wtick(void);
// для измерения времени, но мы ими не пользуемся
// все остальные типа int
// 0 - MPI_SUCCESS
// иначе - ошибки
```

#### 4.
Код ошибки никто не проверяет по умолчанию
По умолчанию при любой ошибке MPI подсистема убивает процесс
Можно зарегистрировать обработчик, чтобы написать сообщение об ошибке, но продолжить нельзя. 
`MPI_Errorhandler_set` - установить обработчик


g++ -I ... -c file.cpp 
mpicxx -c file.cpp

./a.out n m === mpi -np 1 ./a.out n m
gdb --args ./a.out 10 3
```gdb
> r
.
.
.
mpirun -np 4 ./a.out 10 3
```
В MPI_2 в начальный момент программа работает одна, и только потом запускается ещё 3

Можно запустить со списком узлов
mpirun -np 4 список_узлов ./a.out 10 3

В stdout выводит только 1 процесс
stdin не существует
У всех процессов аргументы командной строки одинаковые
Как отлаживать? 4 процесса - 4 отладчика - нужны виртуальные мониторы
```bash
konsole & # & - в фоновом режиме
konsole -e man ls # в другой консоли выполнить man ls
```

```bash
mpirun -np 4 konsole -e gdb --args ./a.ouut 10 3
# открывается 4 консоли нужно будет 4 раза нажать r и в сломаном процессе будем искать ошибку
```

### Программа

```cpp
// Потому что FORTRAN
int MPI_Init(int *argc, char ***argv);
int MPI_Finalize(void);
int MPI_Init(int *argc, char ***argv) {
	
}

int main (int argc, char *argv[]) {
	MPI_Init(&argc, &argv); // это должна быть первая содержательная строка
	// mpirun -np 4
	// из-за этого нельзя делать ничего, что меняет состояние процессора
	// открывать файл, и тд
	...
	if (...) { // ТАК ДЕЛАТЬ НЕ НАДО :
		MPI_Finalize();
		return 1;
	} // ИНАЧЕ ПЛОХО
	printf("Hello\n"); // Так делать тоже не стоит, будет 4 принта
	...
	MPI_Finalize();
	return 0; // не все процессоры дойдут до этой сроки, поэтому 
	// лучше возвращать 0
}
```

## Несколько определений
Сообщение - неделимый кусок информации у которого есть несколько полей
Обмен сообщениями:
- Попарный - участвует любые 2 процесса из одной группы процессоров 1 -> 2. Каждый процессор имеет свой идентификатор группы
- Коллективный обмен - все процессы в одной группе
	1) Один -> всем
	2) Все -> одному (сделать операцию, чтобы данные не увеличивались reduce,  или собрали данные со всех, но тогда память кратно увеличивается)
	3)  Все -> всем (reduce)
идентификатор группы (коммуникатор):
после MPI_Init есть 1 группа
идентификатор MPI_COMM_WORLD
p: 0 ... p - 1
Новые группы - подгруппы старой

один -> всем
```
for (k = 1; k < p; k++) {
	отправка 0 k-му
}
```

Но это не корректно, ведь как я процесс получит данные и теперь отправка будет:
- За log2(p)
- Оптимальный выбор

Если кластер дешёвый на Ethernet, то используют Broadcast

Аналогично все -> одному

Сообщения также бывают:
- Синхронные (тот кто отправил, блокируется до получения (получатель итак блокируется))
- Асинхронные (отправитель не блокируется). Сообщения переходят во внутренний буффер (оперативка, кэш Infiniband адаптера)
Изначально было:
- Попарный - асинхронный, естли влзает в буффер
- Не попарный - всегда синхронный
Сейчас:
- Маленькие данные - асинхронный
- большие (не поместилось в кэш) - синхронные

Пример DEADLOCK:
Пусть обмениваются процессы A и B
```cpp
if (k == A) {
	A -> B; // send
	A <- B; // receive
}
if (k == B) {
	B -> A; // send
	B <- A; // receive
}
```
Правильное решение
```cpp
if (k == A) {
	A -> B; // send
	A <- B; // receive
}
if (k == B) {
	B <- A; // receive
	B -> A; // send
}
```
Deadlock:

```cpp
if (k == A) {
	src = k;
	dst = k + 1;
}
if (k == B) {
	src = k;
	dst = k - 1;
}
send
receive
```

#
```cpp
double t = clock();
solve(...);
getreusage()
```

# Profiler
Как узнать, какая часть программы работает долго?
`-pg` - тег для профайлера
`-g` - debug
```bash
g++ -g -pg -O0
g++ -g -pg -O1
g++ -g -pg -O2
g++ -g -pg -O3
```

```shell
./a.out 6000 30 ...
$ ls
# gmon.out - файл с логами
# замеряет время и количество вызовов функций
# Считается утилитой gprof
$ gprof ./a.out
# -O3
# 99% 1solve - процент времени
# 0% main
# -O2
# 98% mult_blocks
# ...
# -O1
# -O0 - смотрим количество вызовов


```